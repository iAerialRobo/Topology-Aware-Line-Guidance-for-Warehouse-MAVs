# æ¨¡å—å¯¼å…¥åŒºï¼ˆImport Sectionï¼‰
import time
import math
import threading
import os
from statistics import mode, StatisticsError
import csv
import numpy as np
import cv2
import rospy
from dronekit import connect, VehicleMode, LocationGlobalRelative
from pymavlink import mavutil
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from rospy import Rate
from gazebo_msgs.msg import ModelStates
from tf.transformations import euler_from_quaternion



# è¿æ¥ Gazebo ä»¿çœŸä¸­çš„æ— äººæœºï¼ˆIRIS æœºå‹ï¼‰ï¼Œä½¿ Python è„šæœ¬å¯ä»¥é€šè¿‡ DroneKit æ§åˆ¶ä»¿çœŸä¸­çš„é£è¡Œå™¨
# Connect to the simulated vehicle in Gazebo
print("Connecting to the vehicle...")
connection_string = 'tcp:127.0.0.1:5762'
vehicle = connect(connection_string, wait_ready=True, baud=57600)
print("Connected to IRIS")


# ï¼ˆæ— äººæœºæ§åˆ¶æŒ‡ä»¤æ¨¡å—ï¼‰Drone Commands
# åŒ…æ‹¬condition_yawï¼Œsend_ned_velocityï¼Œarm_and_takeoffï¼Œhoverï¼Œland
# rotate_clockwise_90ï¼Œrotate_counterclockwise_90


# condition_yaw ï¼šSet yaw angle via MAVLink
# Rotate the MAV to a specified yaw angle, supporting either absolute or relative heading.
# Set relative=True for relative heading, and relative=False for absolute heading.
def condition_yaw(vehicle, heading, relative=False):
    """
    Send MAV_CMD_CONDITION_YAW message to point vehicle at a specified heading (in degrees).

    """
    if relative:
        is_relative = 1
    else:
        is_relative = 0

    if heading > 0:
        direction = 1
    else:
        direction = -1

    # create the CONDITION_YAW command using command_long_encode()
    msg = vehicle.message_factory.command_long_encode(
        0, 0,  # target system, target component
        mavutil.mavlink.MAV_CMD_CONDITION_YAW,  # command
        0,  # confirmation
        abs(heading),  # param 1, yaw in degrees
        0,  # param 2, yaw speed deg/s
        direction,  # param 3, direction -1 ccw, 1 cw
        is_relative,  # param 4, relative offset 1, absolute angle 0
        0, 0, 0)  # param 5 ~ 7 not used

    # send command to vehicle
    vehicle.send_mavlink(msg)

# Send NED velocity to control motion
def send_ned_velocity(vehicle, velocity_x, velocity_y, velocity_z, duration, frequency=10):
    """
    Move vehicle in direction based on specified velocity vectors.
    Args:
        vehicle: Dronekit vehicle object.
        velocity_x (float): Forward velocity in m/s.
        velocity_y (float): Sideward velocity in m/s.
        velocity_z (float): Downward/upward velocity in m/s.
        duration (float): Duration to send velocity commands.
        frequency (int): Command update frequency in Hz (default: 20 Hz).
    """
    msg = vehicle.message_factory.set_position_target_local_ned_encode(
        0, 0, 0,  # target system, target component
        mavutil.mavlink.MAV_FRAME_BODY_OFFSET_NED,  # frame
        0b0000111111000111,  # type_mask (only speeds enabled)
        0, 0, 0,  # x, y, z positions (not used)
        velocity_x, velocity_y, velocity_z,  # x, y, z velocity in m/s
        0, 0, 0,  # x, y, z acceleration (not supported yet, ignored in GCS_Mavlink)
        0, 0)  # yaw, yaw_rate (not supported yet, ignored in GCS_Mavlink)

    # Send the velocity command repeatedly for the specified duration
    interval = 1.0 / frequency
    start_time = time.time()
    while time.time() - start_time < duration:
        vehicle.send_mavlink(msg)
        time.sleep(interval)  # Send at defined frequency

# Arm and take off to target altitude
def arm_and_takeoff(target_altitude):
    print("Arming motors")
    vehicle.mode = VehicleMode("GUIDED")
    vehicle.armed = True

    while not vehicle.armed:
        print("Waiting for arming...")
        time.sleep(1)

    print("Taking off")
    vehicle.simple_takeoff(target_altitude)

    while True:
        altitude = vehicle.location.global_relative_frame.alt
        print("Altitude: ", altitude)
        if altitude >= target_altitude * 0.9:
            print("Reached target altitude")
            break
        time.sleep(1)
    print("Hovering for 2 seconds")
    time.sleep(2)
    print("Hover complete")

# Hover in place for given time
def hover(vehicle, hover_time):

    print("Hovering in place for", hover_time, "seconds.")

    # å‘é€é›¶é€Ÿåº¦æŒ‡ä»¤ä»¥åœæ­¢æ— äººæœºçš„æ‰€æœ‰ç§»åŠ¨ï¼ˆæ‚¬åœï¼‰
    send_ned_velocity(vehicle, 0, 0, 0, hover_time)

    # æ‚¬åœè®¡æ—¶
    time.sleep(hover_time)

    print("Hover complete.")

# Land and stop image subscription
def land(camera_subscriber):
    print("Landing")
    vehicle.mode = VehicleMode("LAND")

    # ç­‰å¾…æ— äººæœºé™è½å¹¶è§£é™¤æ­¦è£…
    while vehicle.armed:
        time.sleep(1)

    print("Disarming motors")
    vehicle.armed = False

    # å–æ¶ˆè®¢é˜…æ‘„åƒå¤´è¯é¢˜
    if camera_subscriber:
        camera_subscriber.unregister()  # å–æ¶ˆè®¢é˜…
        print("Camera subscriber unregistered.")


# å…¨å±€å˜é‡å®šä¹‰
data_lock = threading.Lock()  # æ•°æ®è®¿é—®é”
rotation_start_time = None
rotation_end_time = None
rotation_duration = None
is_rotating = False

# Rotate 90Â° CW and record time
def rotate_clockwise_90(vehicle):
    """é¡ºæ—¶é’ˆæ—‹è½¬90åº¦ï¼ˆå¸¦å®Œæ•´æ—¶é—´è®°å½•ï¼‰"""
    global rotation_start_time, rotation_end_time, rotation_duration, is_rotating

    with data_lock:
        rotation_start_time = time.time()  # è®°å½•ç»å¯¹å¼€å§‹æ—¶é—´
        is_rotating = True

    current_yaw = math.degrees(vehicle.attitude.yaw)
    target_yaw = (current_yaw + 90) % 360
    condition_yaw(vehicle, heading=target_yaw, relative=False)

    YAW_TOLERANCE = 5
    TIMEOUT = 15
    start_time = time.time()

    while True:
        current_yaw = math.degrees(vehicle.attitude.yaw) % 360
        error = (target_yaw - current_yaw) % 360
        if error > 180: error -= 360

        if abs(error) <= YAW_TOLERANCE:
            print(f"Reached target yaw: {current_yaw:.1f}Â°")
            break

        if time.time() - start_time > TIMEOUT:
            print(f"Rotation timeout at {current_yaw:.1f}Â°")
            break

        time.sleep(0.2)

    with data_lock:
        rotation_end_time = time.time()
        rotation_duration = rotation_end_time - rotation_start_time
        is_rotating = False
        print(f"Rotation completed in {rotation_duration:.2f}s")

    return rotation_start_time, rotation_end_time, rotation_duration  # âœ… **æ·»åŠ è¿”å›å€¼**

# Rotate 90Â° CCW and record time
def rotate_counterclockwise_90(vehicle):
    """é€†æ—¶é’ˆæ—‹è½¬90åº¦ï¼ˆå¸¦å®Œæ•´æ—¶é—´è®°å½•ï¼‰"""
    global rotation_start_time, rotation_end_time, rotation_duration, is_rotating

    with data_lock:
        rotation_start_time = time.time()  # è®°å½•ç»å¯¹å¼€å§‹æ—¶é—´
        is_rotating = True

    current_yaw = math.degrees(vehicle.attitude.yaw)
    target_yaw = (current_yaw - 90) % 360
    condition_yaw(vehicle, heading=target_yaw, relative=False)

    YAW_TOLERANCE = 5
    TIMEOUT = 15
    start_time = time.time()

    while True:
        current_yaw = math.degrees(vehicle.attitude.yaw) % 360
        error = (current_yaw - target_yaw) % 360
        if error > 180: error -= 360

        if abs(error) <= YAW_TOLERANCE:
            print(f"Reached target yaw: {current_yaw:.1f}Â°")
            break

        if time.time() - start_time > TIMEOUT:
            print(f"Rotation timeout at {current_yaw:.1f}Â°")
            break

        time.sleep(0.2)

    with data_lock:
        rotation_end_time = time.time()
        rotation_duration = rotation_end_time - rotation_start_time
        is_rotating = False
        print(f"Rotation completed in {rotation_duration:.2f}s")

    return rotation_start_time, rotation_end_time, rotation_duration  # âœ… **æ·»åŠ è¿”å›å€¼**

# Calculate yaw angle from image deviation
sensitivity = 20	# higher number, sensitive to small deviation
def calculate_yaw_angle(frame_width, deviation, sensitivity, max_yaw_angle=30):
    """
       Calculate yaw angle based on deviation from center.
       Args:
           frame_width (int): Width of the image frame.
           deviation (float): Deviation of the detected center from the frame center.
           sensitivity (float): Sensitivity factor to control the yaw response.
           max_yaw_angle (float): Maximum yaw angle to prevent oversteering (default: 30 degrees).

       Returns:
           float: Calculated yaw angle in degrees.
       """
    yaw_angle = math.atan(deviation / (frame_width * sensitivity))
    yaw_angle = math.degrees(yaw_angle)
    # Clamp the yaw angle within the max limits
    return max(-max_yaw_angle, min(yaw_angle, max_yaw_angle))



# å›¾åƒå¤„ç†ä¸è¯†åˆ«æ¨¡å—ï¼ˆImage Processingï¼‰
# åŒ…æ‹¬detect_yellow_line,follow_yellow_line,calculate_yellow_line_offset,calculate_ratio_dict
# analyze_trends_in_bins,identify_marker_shape_and_orientation,plot_white_pixel_ratios,ShapeCodeProcessor ç±»
# process_image_and_get_shape_code

# Calculate white pixel ratio per bin
bin_size = 10  # è®¾ç½® bin_sizeï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
def calculate_ratio_dict(image, bin_size):
    # è·å–å›¾åƒçš„é«˜åº¦ (height) å’Œå®½åº¦ (width)ã€‚
    height, width = image.shape
    # å°†å›¾åƒçš„å®½åº¦å’Œé«˜åº¦åˆ†åˆ«é™¤ä»¥ bin_sizeï¼Œå¾—åˆ°å®½åº¦æ–¹å‘å’Œé«˜åº¦æ–¹å‘çš„å—æ•°é‡ (bin_width å’Œ bin_height)ã€‚
    bin_width = width // bin_size
    bin_height = height // bin_size
    # åˆå§‹åŒ–ä¸¤ä¸ªç©ºå­—å…¸ï¼Œåˆ†åˆ«ç”¨äºå­˜å‚¨å®½åº¦æ–¹å‘å’Œé«˜åº¦æ–¹å‘çš„ç™½è‰²åƒç´ æ¯”ä¾‹ã€‚
    white_pixel_ratios_width = {}
    white_pixel_ratios_height = {}

    # å¼€å§‹ä¸€ä¸ªå¾ªç¯ï¼Œç”¨äºè®¡ç®—æ¯ä¸€å—çš„ç™½è‰²åƒç´ æ¯”ä¾‹ã€‚
    # start å˜é‡è¡¨ç¤ºå½“å‰å—çš„èµ·å§‹åˆ—ï¼Œend å˜é‡è¡¨ç¤ºå½“å‰å—çš„ç»“æŸåˆ—ï¼ˆä¿è¯ä¸è¶…è¿‡å›¾åƒçš„å®½åº¦ï¼‰ã€‚
    for i in range(bin_width):
        start = i * bin_size
        end = min((i + 1) * bin_size, width)
        # è®¡ç®—å½“å‰å—ä¸­çš„ç™½è‰²åƒç´ æ•°ï¼ˆåƒç´ å€¼ç­‰äº255ï¼‰ã€‚
        white_pixels = np.sum(image[:, start:end] == 255)
        # è®¡ç®—å½“å‰å—ä¸­çš„æ€»åƒç´ æ•°ã€‚
        total_pixels = (end - start) * height
        # è®¡ç®—ç™½è‰²åƒç´ æ¯”ä¾‹ï¼Œå¹¶å°†å…¶å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸‰ä½ã€‚
        ratio = round(white_pixels / total_pixels, 3)
        # å°†è®¡ç®—å‡ºçš„ç™½è‰²åƒç´ æ¯”ä¾‹å­˜å‚¨åœ¨ white_pixel_ratios_width å­—å…¸ä¸­ï¼Œé”®ä¸ºå½“å‰å—çš„ç´¢å¼• iã€‚
        white_pixel_ratios_width[i] = ratio

    # å¼€å§‹å¦ä¸€ä¸ªå¾ªç¯ï¼Œç”¨äºè®¡ç®—é«˜åº¦æ–¹å‘æ¯ä¸€å—çš„ç™½è‰²åƒç´ æ¯”ä¾‹ã€‚
    # start å˜é‡è¡¨ç¤ºå½“å‰å—çš„èµ·å§‹è¡Œï¼Œend å˜é‡è¡¨ç¤ºå½“å‰å—çš„ç»“æŸè¡Œï¼ˆä¿è¯ä¸è¶…è¿‡å›¾åƒçš„é«˜åº¦ï¼‰ã€‚
    for i in range(bin_height):
        start = i * bin_size
        end = min((i + 1) * bin_size, height)
        # è®¡ç®—å½“å‰å—ä¸­çš„ç™½è‰²åƒç´ æ•°ï¼ˆåƒç´ å€¼ç­‰äº255ï¼‰ã€‚
        white_pixels = np.sum(image[start:end, :] == 255)
        # è®¡ç®—å½“å‰å—ä¸­çš„æ€»åƒç´ æ•°ã€‚
        total_pixels = (end - start) * width
        # è®¡ç®—ç™½è‰²åƒç´ æ¯”ä¾‹ï¼Œå¹¶å°†å…¶å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸‰ä½ã€‚
        ratio = round(white_pixels / total_pixels, 3)
        # å°†è®¡ç®—å‡ºçš„ç™½è‰²åƒç´ æ¯”ä¾‹å­˜å‚¨åœ¨ white_pixel_ratios_height å­—å…¸ä¸­ï¼Œé”®ä¸ºå½“å‰å—çš„ç´¢å¼• iã€‚
        white_pixel_ratios_height[i] = ratio
    # è¿”å›ä¸¤ä¸ªå­—å…¸ï¼Œåˆ†åˆ«åŒ…å«å®½åº¦æ–¹å‘å’Œé«˜åº¦æ–¹å‘æ¯ä¸€å—çš„ç™½è‰²åƒç´ æ¯”ä¾‹ã€‚
    return white_pixel_ratios_width, white_pixel_ratios_height

# Analyze pixel trend for junction detection
def analyze_trends_in_bins(bins, ratios):
    """
    åˆ†æç™½è‰²åƒç´ æ¯”ç‡çš„å˜åŒ–è¶‹åŠ¿ï¼šä»ä¸€ä¸ªç°‡åˆ°ä¸‹ä¸€ä¸ªç°‡çš„å˜åŒ–æ˜¯å¢åŠ ã€å‡å°‘ï¼Œè¿˜æ˜¯ä¿æŒä¸å˜ã€‚
    ç°‡æ˜¯æŒ‡è‡³å°‘æœ‰2ä¸ªè¿ç»­æ•°æ®ç‚¹çš„ç›¸åŒç™½è‰²åƒç´ æ¯”ç‡ã€‚
    """
    trends = []

    # Step 1: è¿‡æ»¤æ‰ç™½è‰²åƒç´ æ¯”ç‡ä¸º0çš„æ•°æ®ç‚¹
    non_zero_bins = [bin for bin, ratio in zip(bins, ratios) if ratio != 0]
    non_zero_ratios = [ratio for ratio in ratios if ratio != 0]

    # Step 2: æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
    if len(non_zero_ratios) < 2:  # éœ€è¦è‡³å°‘2ä¸ªéé›¶ç‚¹
        return ['constant'] if len(non_zero_ratios) == 1 else []

    # Step 3: è¯†åˆ«ç°‡ï¼šè‡³å°‘2ä¸ªè¿ç»­çš„ç™½è‰²åƒç´ æ¯”ç‡ç›¸åŒçš„æ•°æ®ç‚¹
    clusters = []
    current_cluster = [non_zero_ratios[0]]  # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªç°‡

    for i in range(1, len(non_zero_ratios)):
        if non_zero_ratios[i] == non_zero_ratios[i - 1]:
            current_cluster.append(non_zero_ratios[i])  # è¿ç»­ç›¸åŒæ¯”ç‡ï¼ŒåŠ å…¥å½“å‰ç°‡
        else:
            # ç°‡ç»“æŸæ—¶æ£€æŸ¥æ˜¯å¦æ»¡è¶³è‡³å°‘ä¸¤ä¸ªæ•°æ®ç‚¹
            if len(current_cluster) >= 2:
                clusters.append(current_cluster)
            current_cluster = [non_zero_ratios[i]]  # å¼€å§‹æ–°ç°‡

    # æ£€æŸ¥æœ€åä¸€ä¸ªç°‡æ˜¯å¦ç¬¦åˆæ¡ä»¶
    if len(current_cluster) >= 2:
        clusters.append(current_cluster)

    # è¾“å‡ºç°‡çš„æ•°é‡
    print(f"ç°‡çš„æ•°é‡: {len(clusters)}")

    # Step 4: å¦‚æœåªæœ‰ä¸€ä¸ªç°‡ï¼Œè¿”å› constant
    if len(clusters) == 1:
        return ['constant']

    # Step 5: è®¡ç®—ç°‡ä¸ç°‡ä¹‹é—´çš„å˜åŒ–è¶‹åŠ¿
    for i in range(1, len(clusters)):
        prev_cluster_mean = sum(clusters[i - 1]) / len(clusters[i - 1])  # å‰ä¸€ä¸ªç°‡çš„å¹³å‡æ¯”ç‡
        curr_cluster_mean = sum(clusters[i]) / len(clusters[i])  # å½“å‰ç°‡çš„å¹³å‡æ¯”ç‡

        # åˆ¤æ–­ç°‡çš„å˜åŒ–è¶‹åŠ¿
        if curr_cluster_mean > prev_cluster_mean:
            trends.append('increase')
        elif curr_cluster_mean < prev_cluster_mean:
            trends.append('decrease')
        else:
            trends.append('constant')

    return trends

# Identify shape code and orientation
def identify_junction_shape_and_orientation(width_trends, height_trends):
    # å®šä¹‰è¶‹åŠ¿åˆ¤å®šç»“æœçš„åˆå§‹å€¼ï¼Œé»˜è®¤ä¸º "Unknown"
    shape_orientation = "Unknown"
    shape_code = 1  # Unknown å¯¹åº”çš„æ•°å­—ç¼–ç 

    # åˆ¤æ–­æ ‡è¯†çš„å½¢çŠ¶åŠæœå‘
    if (width_trends == ['constant'] or width_trends == []) and height_trends == ['constant']:
        shape_orientation = "Line"
        shape_code = 2  # Line
    elif width_trends == ['increase', 'decrease'] and height_trends == ['increase', 'decrease']:
        shape_orientation = "Cross"
        shape_code = 3
    elif width_trends == ['decrease'] and (height_trends == ['increase'] or height_trends == ['decrease']):
        shape_orientation = "L (Right)"
        shape_code = 4  # L æœå³
    elif width_trends == ['increase'] and (height_trends == ['decrease'] or height_trends == ['increase']):
        shape_orientation = "L (Left)"
        shape_code = 5  # L æœå·¦
    elif width_trends == ['increase', 'decrease'] and height_trends == ['increase']:
        shape_orientation = "T (Up)"
        shape_code = 6  # T æœä¸Š
    elif width_trends == ['increase', 'decrease'] and height_trends == ['decrease']:
        shape_orientation = "T (Down)"
        shape_code = 7  # T æœä¸‹
    elif width_trends == ['decrease'] and height_trends == ['increase', 'decrease']:
        shape_orientation = "T (Right)"
        shape_code = 8  # T æœå³
    elif width_trends == ['increase'] and height_trends == ['increase', 'decrease']:
        shape_orientation = "T (Left)"
        shape_code = 9  # T æœå·¦
    else:
        shape_orientation = "Unknown"
        shape_code = 1  # Unknown

    # è¾“å‡ºå½¢çŠ¶å’Œæœå‘
    print(f"junction shape and orientation: {shape_orientation}")
    print(f"Shape code: {shape_code}")

    return shape_code

# Wrap trend analysis and return shape code
def plot_white_pixel_ratios(white_pixel_ratios_width, white_pixel_ratios_height, image):


    # å°†å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼ï¼Œæ–¹ä¾¿å¤„ç†
    width_bins = list(white_pixel_ratios_width.keys())
    width_ratios = list(white_pixel_ratios_width.values())

    height_bins = list(white_pixel_ratios_height.keys())
    height_ratios = list(white_pixel_ratios_height.values())

    # å¯¹æ•°æ®è¿›è¡Œä¿®æ­£å¤„ç†ï¼Œå¤„ç†è¿ç»­å€¼ç›¸å·®å°äº0.01çš„æƒ…å†µï¼ˆå®½åº¦æ–¹å‘ï¼‰
    def process_ratios(bins, ratios):
        corrected_bins = []
        corrected_ratios = []
        temp_bins = []
        temp_ratios = []

        for i in range(len(ratios)):
            if not temp_ratios or abs(ratios[i] - temp_ratios[-1]) < 0.01:
                temp_bins.append(bins[i])
                temp_ratios.append(ratios[i])
            else:
                # å¯¹è¿ç»­ç›¸å·®å°äº0.01çš„éƒ¨åˆ†å–å¹³å‡å€¼
                avg_ratio = sum(temp_ratios) / len(temp_ratios)
                corrected_bins.extend(temp_bins)
                corrected_ratios.extend([avg_ratio] * len(temp_ratios))

                # æ¸…ç©ºä¸´æ—¶å­˜å‚¨ï¼Œå¼€å§‹æ–°çš„åˆ†ç»„
                temp_bins = [bins[i]]
                temp_ratios = [ratios[i]]

        # æœ€åå‰©ä½™çš„éƒ¨åˆ†
        if temp_ratios:
            avg_ratio = sum(temp_ratios) / len(temp_ratios)
            corrected_bins.extend(temp_bins)
            corrected_ratios.extend([avg_ratio] * len(temp_ratios))

        return corrected_bins, corrected_ratios

    # ä¿®æ­£åçš„å®½åº¦å’Œé«˜åº¦æ•°æ®
    corrected_width_bins, corrected_width_ratios = process_ratios(width_bins, width_ratios)
    corrected_height_bins, corrected_height_ratios = process_ratios(height_bins, height_ratios)

    # è°ƒç”¨ analyze_trends_in_bins å¤„ç†ä¿®æ­£åçš„å®½åº¦å’Œé«˜åº¦æ•°æ®
    width_trends = analyze_trends_in_bins(corrected_width_bins, corrected_width_ratios)
    height_trends = analyze_trends_in_bins(corrected_height_bins, corrected_height_ratios)


    # è°ƒç”¨ identify_marker_shape_and_orientation æ¥è¯†åˆ«æ ‡å¿—å½¢çŠ¶å’Œæœå‘
    shape_code = identify_junction_shape_and_orientation(width_trends, height_trends)

    return shape_code



# Lateral PID control with dead zone
# å…¨å±€å˜é‡ç”¨äº PID æ§åˆ¶å™¨
integral_error = 0
last_error = 0
# æ·»åŠ ç§¯åˆ†é™å¹…ä»¥é¿å…ç§¯åˆ†é¥±å’Œ
MAX_INTEGRAL = 50  # æœ€å¤§ç§¯åˆ†å€¼é™åˆ¶
def pid_control_with_dead_zone(deviation, Kp, Ki, Kd, dead_zone=0.05):
    global integral_error, last_error

    # æ­»åŒºåˆ¤æ–­
    if abs(deviation) <= dead_zone:
        integral_error = 0  # åå·®åœ¨æ­»åŒºèŒƒå›´å†…ï¼Œæ¸…ç©ºç§¯åˆ†é¡¹
        return 0

    # PID è®¡ç®—
    integral_error += deviation
    integral_error = max(min(integral_error, MAX_INTEGRAL), -MAX_INTEGRAL)  # é™å¹…
    derivative_error = deviation - last_error
    last_error = deviation

    pid_output = (Kp * deviation + Ki * integral_error + Kd * derivative_error)
    return pid_output


# Get yellow line center (cx)
def detect_yellow_line(frame, lower_yellow, upper_yellow):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    mask_raw = cv2.inRange(hsv, lower_yellow, upper_yellow)
    mask_blurred = cv2.medianBlur(mask_raw, 5)
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask_blurred, cv2.MORPH_CLOSE, kernel)
    moments = cv2.moments(mask)
    if moments["m00"] > 0:
        cx = int(moments["m10"] / moments["m00"])
    else:
        cx = -1
    return cx

# Follow yellow line using PID control
def follow_yellow_line(vehicle, frame):


    # é»„è‰²èŒƒå›´çš„ HSV å€¼
    lower_yellow = np.array([18, 84, 140])
    upper_yellow = np.array([175, 255, 255])

    # æ£€æµ‹é»„è‰²çº¿çš„ä¸­å¿ƒä½ç½®
    cx = detect_yellow_line(frame, lower_yellow, upper_yellow)

    # è·å–å›¾åƒå®½åº¦å’Œä¸­å¿ƒä½ç½®
    frame_width = frame.shape[1]
    frame_center = frame_width // 2

    # åœ¨å›¾åƒä¸Šç»˜åˆ¶ frame_center çš„çº¢è‰²ç‚¹
    frame_height = frame.shape[0]
    cv2.circle(frame, (frame_center, frame_height // 2), 5, (0, 0, 255), -1)  # çº¢è‰²ç‚¹ (B, G, R)

    if cx != -1:
        # åœ¨å›¾åƒä¸Šç»˜åˆ¶ cx çš„è“è‰²ç‚¹
        cv2.circle(frame, (cx, frame_height // 2), 5, (255, 0, 0), -1)  # è“è‰²ç‚¹

    # å¦‚æœæœªæ£€æµ‹åˆ°é»„è‰²çº¿ï¼Œæ‚¬åœ
    if cx == -1:
        print("Yellow line not detected. Hovering...")
        hover(vehicle, hover_time=0)  # ç¤ºä¾‹ï¼šæ— äººæœºæ‚¬åœ
        return

    # è®¡ç®—åå·®å€¼
    deviation = cx - frame_center

    # å½’ä¸€åŒ–åå·®å€¼åˆ° [-1, 1]ï¼Œé¿å…é€Ÿåº¦æ˜ å°„è¶…å‡ºæ— äººæœºèƒ½åŠ›
    normalized_deviation = deviation / frame_center

    # PID å‚æ•°
    Kp, Ki, Kd = 1.0, 0.02, 0.5
    dead_zone = 0.05  # æ­»åŒºä¹ŸæŒ‰å½’ä¸€åŒ–å€¼è°ƒæ•´

    # ä½¿ç”¨ PID è®¡ç®—æ¨ªå‘è°ƒæ•´
    lateral_adjustment = pid_control_with_dead_zone(normalized_deviation, Kp, Ki, Kd, dead_zone)

    # è°ƒæ•´æ¨ªå‘é€Ÿåº¦
    forward_speed = 0.1  # å‰è¿›é€Ÿåº¦å¢åŠ ä»¥æµ‹è¯•æ•ˆæœ
    lateral_speed = lateral_adjustment * 0.5  # æ ¹æ®æ— äººæœºç‰¹æ€§ç¼©æ”¾
    send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=lateral_speed, velocity_z=0, duration=0.1)

    print(f"Normalized Deviation: {normalized_deviation:.2f}, Lateral Adjustment: {lateral_speed:.2f}")

# Compute pixel deviation of yellow line
def calculate_yellow_line_offset(frame):
    # é»„è‰²èŒƒå›´çš„ HSV å€¼
    lower_yellow = np.array([18, 84, 140])
    upper_yellow = np.array([175, 255, 255])

    # æ£€æµ‹é»„è‰²çº¿çš„ä¸­å¿ƒä½ç½®
    cx = detect_yellow_line(frame, lower_yellow, upper_yellow)

    # è·å–å›¾åƒå®½åº¦å’Œä¸­å¿ƒä½ç½®
    frame_width = frame.shape[1]
    frame_center = frame_width // 2

    if cx == -1:
        # å¦‚æœæœªæ£€æµ‹åˆ°é»„çº¿ï¼Œåˆ™è¿”å›åç§»é‡ä¸º 0
        return 0

    # è®¡ç®—åå·®å€¼
    deviation = cx - frame_center
    return deviation

# Class for smoothing shape codes
class ShapeCodeProcessor:
    def __init__(self, window_size=5):
        self.window_size = window_size
        self.window = []

    def process_code(self, new_code):
        # æ·»åŠ æ–°ä»£ç åˆ°çª—å£
        self.window.append(new_code)
        if len(self.window) > self.window_size:
            self.window.pop(0)

        try:
            # å°è¯•è®¡ç®—ä¼—æ•°
            dominant_code = mode(self.window)
        except StatisticsError:
            # å¦‚æœæ²¡æœ‰å”¯ä¸€ä¼—æ•°ï¼Œè¿”å›çª—å£ä¸­çš„ç¬¬ä¸€ä¸ªå€¼
            dominant_code = self.window[0]

        return dominant_code

# å¼•å…¥æ»‘åŠ¨çª—å£å¤„ç†å™¨
shape_code_processor = ShapeCodeProcessor(window_size=5)

# Extract smoothed shape code from image
def process_image_and_get_shape_code(image):
    # ä½¿ç”¨å±€éƒ¨å˜é‡è€Œéå…¨å±€å˜é‡
    local_last_shape_code = last_shape_code

    # Resize the image to a smaller resolution
    new_width, new_height = 400, 400  # ç›®æ ‡å°ºå¯¸
    small_image = cv2.resize(image, (new_width, new_height))

    # Convert the frame to HSV color space
    hsv = cv2.cvtColor(small_image, cv2.COLOR_BGR2HSV)

    # å®šä¹‰çº¢è‰²çš„ HSV èŒƒå›´
    lower_red1, upper_red1 = np.array([0, 100, 100]), np.array([10, 255, 255])
    lower_red2, upper_red2 = np.array([170, 100, 100]), np.array([180, 255, 255])

    # åˆ›å»ºçº¢è‰²æ©ç 
    mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask_red = cv2.bitwise_or(mask_red1, mask_red2)

    # è®¡ç®—çº¢è‰²åƒç´ çš„æ•°é‡
    red_pixel_count = cv2.countNonZero(mask_red)


    # å¦‚æœæ£€æµ‹åˆ°è¶³å¤Ÿçš„çº¢è‰²åƒç´ ï¼Œè¿”å›å½¢çŠ¶ä»£ç  0ï¼Œä¸åšåç»­æ“ä½œ
    if red_pixel_count > 350:  # é˜ˆå€¼å¯è°ƒæ•´
        print("Red detected: Marking as shape code 0")
        local_last_shape_code = 0  # æ›´æ–°å±€éƒ¨å˜é‡
        smoothed_code = shape_code_processor.process_code(0)
        return 0, smoothed_code

    # å®šä¹‰é»„è‰²åœ¨ HSV è‰²å½©ç©ºé—´ä¸­çš„èŒƒå›´,lower_yellow å’Œ upper_yellow åˆ†åˆ«æ˜¯é»„è‰²çš„ä¸‹é™å’Œä¸Šé™ HSV å€¼ã€‚
    lower_yellow = np.array([18, 84, 140])
    upper_yellow = np.array([175, 255, 255])

    # é»„è‰²æ©ç åŠå½¢æ€å­¦å¤„ç†
    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
    mask_blurred = cv2.medianBlur(mask_yellow, 5)
    kernel = np.ones((5, 5), np.uint8)
    mask_morph = cv2.morphologyEx(mask_blurred, cv2.MORPH_CLOSE, kernel)

    # è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°è®¡ç®—ç™½è‰²åƒç´ æ¯”ä¾‹
    bin_size = 10  # åˆ†åŒºå¤§å°
    white_pixel_ratios_width, white_pixel_ratios_height = calculate_ratio_dict(mask_morph, bin_size)

    # è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°ç»˜å›¾å¹¶è¿”å›å½¢çŠ¶ä»£ç 
    shape_code = plot_white_pixel_ratios(
        white_pixel_ratios_width, white_pixel_ratios_height, mask_morph
    )

    # å¦‚æœå½¢çŠ¶ä»£ç ä¸º 1ï¼Œè°ƒæ•´ä¸ºä¸Šä¸€å¸§çš„å½¢çŠ¶ä»£ç 
    if shape_code == 1:
        if last_shape_code is not None:  # å¦‚æœä¸Šä¸€å¸§å½¢çŠ¶ä»£ç å­˜åœ¨
            print(f"Unknown shape detected. Adjusting to last shape code: {last_shape_code}")
            shape_code = last_shape_code  # è°ƒæ•´ä¸ºä¸Šä¸€å¸§å½¢çŠ¶ä»£ç 
        else:
            print("Unknown shape detected. No last shape code available. Keeping as 1.")

    # å¯¹å½¢çŠ¶ä»£ç è¿›è¡Œå¹³æ»‘å¤„ç†
    smoothed_code = shape_code_processor.process_code(shape_code)

    # æœ€åæ›´æ–°å±€éƒ¨å˜é‡
    local_last_shape_code = smoothed_code

    # è¿”å›åŸå§‹å½¢çŠ¶ä»£ç å’Œå¹³æ»‘åçš„å½¢çŠ¶ä»£ç 
    return shape_code, smoothed_code


# Create a CvBridge object to convert ROS Image messages to OpenCV images
bridge = CvBridge()
forward_speed = 0.1  # Default forward speed
# å¼•å…¥å˜é‡è®°å½•ä¸Šä¸€å¸§çš„å½¢çŠ¶ä»£ç 
last_shape_code = 0
# å¼•å…¥è®¡æ•°å˜é‡
t_right_count = 0  # åˆå§‹åŒ–è®¡æ•°å˜é‡
t_left_count = 0
camera_subscriber = None
cross_count = 0
phase = 1
# å…¨å±€å˜é‡ç”¨äºæ§åˆ¶ä¸»å¾ªç¯
pause_movement = False
exit_flag = False  # ç”¨äºæ ‡è®°æ˜¯å¦é€€å‡ºä¸»å¾ªç¯
# å¼•å…¥å˜é‡è®°å½•å½¢çŠ¶è·Ÿè¸ªçŠ¶æ€
tracking_active = False  # ç”¨äºæ ‡è®°æ˜¯å¦æ­£åœ¨è·Ÿè¸ª4åˆ°8çš„è¿‡æ¸¡
tracking_state = None  # è·Ÿè¸ªçš„ç›®æ ‡çŠ¶æ€ï¼ˆ'T_left' æˆ– 'Cross'ç­‰ç­‰ï¼‰
image_counter = 0

# åˆå§‹åŒ– ROS èŠ‚ç‚¹
rospy.init_node('drone_data_logger', anonymous=True)

# å®šä¹‰å…¨å±€å˜é‡
current_pose = None
current_twist = None
current_pitch = None
current_roll = None
current_yaw = None


directory_03 = '/home/dym/course0yuan_data_03'
data_file_path_03 = os.path.join(directory_03, 'log_03.csv')
# æ£€æŸ¥å¹¶åˆ›å»ºç›®å½•
if not os.path.exists(directory_03):
    os.makedirs(directory_03)
# åˆå§‹åŒ–è®¡æ—¶å™¨æ ‡å¿—
start_timer_03_initialized = False
start_time_03 = None
# åˆå§‹åŒ– CSV æ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´ï¼ˆå«å•ä½ï¼‰
with open(data_file_path_03, 'w', newline='') as csvfile_03:
    csv_writer_03 = csv.writer(csvfile_03)
    csv_writer_03.writerow([
        "Timestamp (s)", "Position_X (m)", "Position_Y (m)", "Position_Z (m)",
        "Speed_X (m/s)", "Speed_Y (m/s)", "Speed_Z (m/s)",
        "Pitch (rad)", "Roll (rad)", "Yaw (rad)", "Image_Center_Offset (pixels)"
    ])


directory_13 = '/home/dym/course1yuan_data_13'
data_file_path_13 = os.path.join(directory_13, 'log_13.csv')
# æ£€æŸ¥å¹¶åˆ›å»ºç›®å½•
if not os.path.exists(directory_13):
    os.makedirs(directory_13)
# åˆå§‹åŒ–è®¡æ—¶å™¨æ ‡å¿—
start_timer_13_initialized = False
start_time_13 = None
# åˆå§‹åŒ– CSV æ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´ï¼ˆå«å•ä½ï¼‰
with open(data_file_path_13, 'w', newline='') as csvfile_13:
    csv_writer_13 = csv.writer(csvfile_13)
    csv_writer_13.writerow([
        "Timestamp (s)", "Position_X (m)", "Position_Y (m)", "Position_Z (m)",
        "Speed_X (m/s)", "Speed_Y (m/s)", "Speed_Z (m/s)",
        "Pitch (rad)", "Roll (rad)", "Yaw (rad)", "Image_Center_Offset (pixels)",
        "Rotation Start Time (s)", "Rotation End Time (s)", "Rotation Duration (s)"
    ])


directory_23 = '/home/dym/course2yuan_data_23'
data_file_path_23 = os.path.join(directory_23, 'log_23.csv')
# æ£€æŸ¥å¹¶åˆ›å»ºç›®å½•
if not os.path.exists(directory_23):
    os.makedirs(directory_23)
# åˆå§‹åŒ–è®¡æ—¶å™¨æ ‡å¿—
start_timer_23_initialized = False
start_time_23 = None
# åˆå§‹åŒ– CSV æ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´ï¼ˆå«å•ä½ï¼‰
with open(data_file_path_23, 'w', newline='') as csvfile_23:
    csv_writer_23 = csv.writer(csvfile_23)
    csv_writer_23.writerow([
        "Timestamp (s)", "Position_X (m)", "Position_Y (m)", "Position_Z (m)",
        "Speed_X (m/s)", "Speed_Y (m/s)", "Speed_Z (m/s)",
        "Pitch (rad)", "Roll (rad)", "Yaw (rad)", "Image_Center_Offset (pixels)",
        "Rotation Start Time (s)", "Rotation End Time (s)", "Rotation Duration (s)"
    ])


directory_53 = '/home/dym/course3yuan_data_53'
data_file_path_53 = os.path.join(directory_53, 'log_53.csv')
# æ£€æŸ¥å¹¶åˆ›å»ºç›®å½•
if not os.path.exists(directory_53):
    os.makedirs(directory_53)
# åˆå§‹åŒ–è®¡æ—¶å™¨æ ‡å¿—
start_timer_53_initialized = False
start_time_53 = None
# åˆå§‹åŒ– CSV æ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´ï¼ˆå«å•ä½ï¼‰
with open(data_file_path_53, 'w', newline='') as csvfile_53:
    csv_writer_53 = csv.writer(csvfile_53)
    csv_writer_53.writerow([
        "Timestamp (s)", "Position_X (m)", "Position_Y (m)", "Position_Z (m)",
        "Speed_X (m/s)", "Speed_Y (m/s)", "Speed_Z (m/s)",
        "Pitch (rad)", "Roll (rad)", "Yaw (rad)", "Image_Center_Offset (pixels)",
        "Rotation Start Time (s)", "Rotation End Time (s)", "Rotation Duration (s)"
    ])

# ROS callback to update MAV pose/yaw
def model_states_callback(data):
    global current_pose, current_twist, current_pitch, current_roll, current_yaw
    drone_name = "iris"

    if drone_name in data.name:
        index = data.name.index(drone_name)
        current_pose = data.pose[index]
        current_twist = data.twist[index]

        # æå–å››å…ƒæ•°
        quaternion = (
            current_pose.orientation.x,
            current_pose.orientation.y,
            current_pose.orientation.z,
            current_pose.orientation.w,
        )

        # å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’ï¼ˆå¼§åº¦ï¼‰
        current_roll, current_pitch, current_yaw = euler_from_quaternion(quaternion)

# è®¢é˜… Gazebo çš„ /gazebo/model_states è¯é¢˜
rospy.Subscriber("/gazebo/model_states", ModelStates, model_states_callback)


def image_callback_03(msg):
    global camera_subscriber, t_right_count, last_shape_code, pause_movement, exit_flag, tracking_active, image_counter
    global start_timer_03_initialized, start_time_03
    global current_pose, current_twist, current_pitch, current_roll, current_yaw  # ä½¿ç”¨æ–°çš„å…¨å±€å˜é‡

    print(f"Last shape code before update: {last_shape_code}")
    if not start_timer_03_initialized:
        start_time_03 = time.time()
        start_timer_03_initialized = True
        print("Timer initialized for image_callback_03.")

    timestamp = time.time() - start_time_03

    # è·å–æ— äººæœºçŠ¶æ€ä¿¡æ¯
    position = current_pose.position if current_pose else None
    velocity = current_twist.linear if current_twist else None
    # ä½¿ç”¨ Gazebo æå–çš„å§¿æ€ä¿¡æ¯
    pitch = current_pitch if current_pitch is not None else None
    roll = current_roll if current_roll is not None else None
    yaw = current_yaw if current_yaw is not None else None

    # è½¬æ¢å›¾åƒ
    cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
    small_image = cv2.resize(cv_image, (400, 400))
    # è®¡ç®—å›¾åƒä¸­å¿ƒä¸é»„çº¿ä¸­å¿ƒçš„è·ç¦»
    yellow_line_offset = calculate_yellow_line_offset(small_image)  # è‡ªå®šä¹‰å‡½æ•°

    # ä¿å­˜æ•°æ®åˆ° CSV æ–‡ä»¶
    with open(data_file_path_03, 'a', newline='') as csvfile_03:
        csv_writer_03 = csv.writer(csvfile_03)
        csv_writer_03.writerow([
            f"{round(timestamp, 2)} s",
            f"{position.x:.2f} m" if position else "N/A",
            f"{position.y:.2f} m" if position else "N/A",
            f"{position.z:.2f} m" if position else "N/A",
            f"{velocity.x:.2f} m/s" if velocity else "N/A",
            f"{velocity.y:.2f} m/s" if velocity else "N/A",
            f"{velocity.z:.2f} m/s" if velocity else "N/A",
            f"{pitch:.2f} rad" if pitch is not None else "N/A",
            f"{roll:.2f} rad" if roll is not None else "N/A",
            f"{yaw:.2f} rad" if yaw is not None else "N/A",
            f"{yellow_line_offset} pixels"
        ])

    print("Data recorded to CSV.")


    # Define the folder to save captured images (JPG format before converting to EPS)
    folder_path = '/home/dym/course0yuan_PID_images'  # course0bian_images,course0yuan_images

    # Create the folder if it does not exist
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    # Generate a unique filename based on the counter value (JPG format)
    image_filename = f"image_{image_counter}.jpg"

    # Increment the counter for the next image
    image_counter += 1

    # Construct the full file path to save the image in JPG format
    file_path = os.path.join(folder_path, image_filename)

    # Save the captured image in JPG format (for now)
    cv2.imwrite(file_path, small_image)
    print(f"Image saved as JPG: {file_path}")

    # Convert the OpenCV image to a NumPy array
    frame = np.array(small_image)  # Use the resized image

    # è·å–åŸä»£ç åŠå¹³æ»‘åçš„å½¢çŠ¶ä»£ç 
    shape_code, smoothed_shape_code = process_image_and_get_shape_code(cv_image)

    # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
    last_shape_code = int(last_shape_code)
    smoothed_shape_code = int(smoothed_shape_code)

    print(f"Checking condition: last_shape_code={last_shape_code}, smoothed_shape_code={smoothed_shape_code}")
    # å¦‚æœå½¢çŠ¶ä»£ç ä¸º4ï¼Œè¿›å…¥é˜¶æ®µ
    if smoothed_shape_code == 4 and not tracking_active:
        print("Shape code 4 detected. Starting transition phase.")
        tracking_active = True

    elif smoothed_shape_code == 8 and tracking_active:
        t_right_count += 1
        tracking_active = False  # é‡ç½®è·Ÿè¸ªçŠ¶æ€

        print(f"T right transition detected. Current count: {t_right_count}")

        if t_right_count == 1:
            print("First T right detected.")
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif t_right_count == 2:
            print("Second T right detected.")
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif t_right_count == 3:
            print("Third T right detected. Position '03' reached.")

            # æš‚åœä¸»å¾ªç¯
            pause_movement = True

            # æ— äººæœºæ‚¬åœ
            hover(vehicle, hover_time=5)

            # åœæ­¢ç›¸æœºè®¢é˜…
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")


            # è®¾ç½®é€€å‡ºæ ‡å¿—ï¼Œé€€å‡ºä¸»å¾ªç¯
            exit_flag = True

    elif smoothed_shape_code == 2:

        # è°ƒç”¨è·¯å¾„è·Ÿè¸ªå‡½æ•°
        follow_yellow_line(vehicle, frame)

    # Display the image
    cv2.imshow("frame", frame)
    cv2.waitKey(10)

    # æ›´æ–°ä¸Šä¸€å¸§å½¢çŠ¶ä»£ç 
    last_shape_code = smoothed_shape_code
    print(f"Last shape code after update: {last_shape_code}")


def image_callback_13(msg):
    global camera_subscriber, t_left_count, cross_count, last_shape_code, pause_movement, exit_flag, image_counter
    global tracking_active, tracking_state
    global start_timer_13_initialized, start_time_13
    global current_pose, current_twist, current_pitch, current_roll, current_yaw  # ä½¿ç”¨æ–°çš„å…¨å±€å˜é‡
    global rotation_start_time, rotation_end_time, rotation_duration, is_rotating

    print(f"Last shape code before processing: {last_shape_code}")

    # **æ·»åŠ æ—¶é—´æˆ³çš„è®¡ç®—**
    if not start_timer_13_initialized:
        start_time_13 = time.time()
        start_timer_13_initialized = True
        print("Timer initialized for image_callback_13.")
        rotation_start_time = None  # é‡ç½®ä»»ä½•å·²æœ‰çš„æ—‹è½¬æ—¶é—´
    timestamp = time.time() - start_time_13  # âœ… **æ·»åŠ è¿™ä¸€è¡Œ**

    with data_lock:
        if is_rotating and rotation_start_time is not None and start_time_13 is not None:
            # æ­£åœ¨æ—‹è½¬ä¸­çš„çŠ¶æ€
            rotation_data = [
                f"{rotation_start_time - start_time_13:.2f}",
                "Rotating",
                "Calculating"
            ]
        elif rotation_duration is not None and rotation_start_time is not None and rotation_end_time is not None and start_time_13 is not None:
            # æ—‹è½¬å®Œæˆåçš„å®Œæ•´è®°å½•
            rotation_data = [
                f"{rotation_start_time - start_time_13:.2f}",
                f"{rotation_end_time - start_time_13:.2f}",
                f"{rotation_duration:.2f}"
            ]
            # å•æ¬¡è®°å½•åé‡ç½®
            rotation_start_time = rotation_end_time = rotation_duration = None
        else:
            # å¦‚æœæ—‹è½¬æ•°æ®æœªåˆå§‹åŒ–ï¼Œé¿å…æŠ¥é”™
            rotation_data = ["N/A", "N/A", "N/A"]


    # è·å–æ— äººæœºçŠ¶æ€ä¿¡æ¯
    position = current_pose.position if current_pose else None
    velocity = current_twist.linear if current_twist else None
    # ä½¿ç”¨ Gazebo æå–çš„å§¿æ€ä¿¡æ¯
    pitch = current_pitch if current_pitch is not None else None
    roll = current_roll if current_roll is not None else None
    yaw = current_yaw if current_yaw is not None else None

    # Convert the ROS image message to an OpenCV image
    cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
    small_image = cv2.resize(cv_image, (300, 300))
    # è®¡ç®—å›¾åƒä¸­å¿ƒä¸é»„çº¿ä¸­å¿ƒçš„è·ç¦»
    yellow_line_offset = calculate_yellow_line_offset(small_image)  # è‡ªå®šä¹‰å‡½æ•°

    # ä¿å­˜æ•°æ®åˆ° CSV
    with open(data_file_path_13, 'a', newline='') as csvfile_13:
        csv_writer_13 = csv.writer(csvfile_13)
        csv_writer_13.writerow([
            f"{round(timestamp, 2)} s",
            f"{position.x:.2f} m" if position else "N/A",
            f"{position.y:.2f} m" if position else "N/A",
            f"{position.z:.2f} m" if position else "N/A",
            f"{velocity.x:.2f} m/s" if velocity else "N/A",
            f"{velocity.y:.2f} m/s" if velocity else "N/A",
            f"{velocity.z:.2f} m/s" if velocity else "N/A",
            pitch, roll, yaw,
            f"{yellow_line_offset} pixels",
            rotation_data[0],  # åŠ¨æ€æ•°æ®
            rotation_data[1],
            rotation_data[2]
        ])

    print("Data recorded to CSV.")

    # Define the folder to save captured images (JPG format before converting to EPS)
    folder_path = '/home/dym/course1yuan_PID_images'  # course0bian_images,course0yuan_images

    # Create the folder if it does not exist
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    # Generate a unique filename based on the counter value (JPG format)
    image_filename = f"image_{image_counter}.jpg"

    # Increment the counter for the next image
    image_counter += 1

    # Construct the full file path to save the image in JPG format
    file_path = os.path.join(folder_path, image_filename)

    # Save the captured image in JPG format (for now)
    cv2.imwrite(file_path, small_image)
    print(f"Image saved as JPG: {file_path}")

    # Convert the OpenCV image to a NumPy array
    frame = np.array(small_image)  # Use the resized image

    # è·å–å¹³æ»‘åçš„å½¢çŠ¶ä»£ç 
    shape_code, smoothed_shape_code = process_image_and_get_shape_code(cv_image)

    # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
    last_shape_code = int(last_shape_code)
    smoothed_shape_code = int(smoothed_shape_code)
    print(f"Checking transition condition: last_shape_code={last_shape_code}, smoothed_shape_code={smoothed_shape_code}")

    ### æ­¥éª¤ 1: æ£€æµ‹å¹¶å¤„ç† T å½¢æ ‡å¿— ###
    if not tracking_active and smoothed_shape_code == 5:
        # å¼€å§‹è·Ÿè¸ª T å·¦è¿‡æ¸¡
        tracking_active = True
        #tracking_state = 'T_left'
        print("Started tracking T left transition.")

    if tracking_active and smoothed_shape_code == 9:
        t_left_count += 1
        print(f"T left transition completed. T left count: {t_left_count}")
        tracking_active = False
        #tracking_state = None

        if t_left_count == 1:
           print("First T left detected")
           pause_movement = True  # æš‚åœä¸»å¾ªç¯
           # âœ… æ­£ç¡®è°ƒç”¨æ—‹è½¬å‡½æ•°ï¼Œè·å–æ—¶é—´æ•°æ®
           rotation_start_time, rotation_end_time, rotation_duration = rotate_counterclockwise_90(vehicle)

           # âœ… é¿å… `NoneType` é”™è¯¯
           if rotation_start_time is not None and rotation_end_time is not None:
               print(f"ğŸ“Œ Rotation Start Time: {rotation_start_time:.2f} s")
               print(f"ğŸ“Œ Rotation End Time: {rotation_end_time:.2f} s")
               print(f"ğŸ“Œ Rotation Duration: {rotation_duration:.2f} s")
           pause_movement = False  # æ¢å¤ä¸»å¾ªç¯
           return

    ### æ­¥éª¤ 2: æ£€æµ‹å¹¶å¤„ç†äº¤å‰æ ‡å¿— ###
    if not tracking_active and smoothed_shape_code == 7:
        # å¼€å§‹è·Ÿè¸ªäº¤å‰è¿‡æ¸¡
        tracking_active = True
        #tracking_state = 'Cross'
        print("Started tracking Cross transition.")

    if tracking_active and smoothed_shape_code == 3:
        cross_count += 1
        print(f"Cross transition completed. Cross count: {cross_count}")
        tracking_active = False
        #tracking_state = None

        if cross_count == 1:
            print("First cross detected.")
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif cross_count == 2:
            print("Second cross detected.")
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif cross_count == 3:
            print("Third cross detected. Position '13' reached.")

            # æš‚åœä¸»å¾ªç¯
            pause_movement = True

            # æ— äººæœºæ‚¬åœ
            hover(vehicle, hover_time=5)

            # åœæ­¢ç›¸æœºè®¢é˜…
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")


            exit_flag = True  # è®¾ç½®é€€å‡ºæ ‡å¿—
    elif smoothed_shape_code == 2 :
        # è°ƒç”¨è·¯å¾„è·Ÿè¸ªå‡½æ•°
        follow_yellow_line(vehicle, frame)

    # Display the image
    cv2.imshow("frame", frame)
    cv2.waitKey(10)
    # æ›´æ–°ä¸Šä¸€å¸§å½¢çŠ¶ä»£ç 
    last_shape_code = smoothed_shape_code
    print(f"Last shape code after update: {last_shape_code}")

def image_callback_23(msg):
    global camera_subscriber, t_left_count, cross_count, last_shape_code, pause_movement, exit_flag, image_counter
    global tracking_active, tracking_state
    global start_timer_23_initialized, start_time_23
    global current_pose, current_twist, current_pitch, current_roll, current_yaw
    global rotation_start_time, rotation_end_time, rotation_duration, is_rotating

    print(f"Last shape code before processing: {last_shape_code}")

    # **æ·»åŠ æ—¶é—´æˆ³çš„è®¡ç®—**
    if not start_timer_23_initialized:
        start_time_23 = time.time()
        start_timer_23_initialized = True
        print("Timer initialized for image_callback_23.")
        rotation_start_time = None  # é‡ç½®ä»»ä½•å·²æœ‰çš„æ—‹è½¬æ—¶é—´
    timestamp = time.time() - start_time_23  # âœ… **æ·»åŠ è¿™ä¸€è¡Œ**

    with data_lock:
        if is_rotating and rotation_start_time is not None and start_time_23 is not None:
            # æ­£åœ¨æ—‹è½¬ä¸­çš„çŠ¶æ€
            rotation_data = [
                f"{rotation_start_time - start_time_23:.2f}",
                "Rotating",
                "Calculating"
            ]
        elif rotation_duration is not None and rotation_start_time is not None and rotation_end_time is not None and start_time_23 is not None:
            # æ—‹è½¬å®Œæˆåçš„å®Œæ•´è®°å½•
            rotation_data = [
                f"{rotation_start_time - start_time_23:.2f}",
                f"{rotation_end_time - start_time_23:.2f}",
                f"{rotation_duration:.2f}"
            ]
            # å•æ¬¡è®°å½•åé‡ç½®
            rotation_start_time = rotation_end_time = rotation_duration = None
        else:
            # å¦‚æœæ—‹è½¬æ•°æ®æœªåˆå§‹åŒ–ï¼Œé¿å…æŠ¥é”™
            rotation_data = ["N/A", "N/A", "N/A"]

    # è·å–æ— äººæœºçŠ¶æ€ä¿¡æ¯
    position = current_pose.position if current_pose else None
    velocity = current_twist.linear if current_twist else None
    pitch = current_pitch if current_pitch is not None else "N/A"
    roll = current_roll if current_roll is not None else "N/A"
    yaw = current_yaw if current_yaw is not None else "N/A"



    # Convert the ROS image message to an OpenCV image
    cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
    small_image = cv2.resize(cv_image, (400, 400))

    # è®¡ç®—å›¾åƒä¸­å¿ƒä¸é»„çº¿ä¸­å¿ƒçš„è·ç¦»
    yellow_line_offset = calculate_yellow_line_offset(small_image)
    # ä¿å­˜æ•°æ®åˆ° CSV
    with open(data_file_path_23, 'a', newline='') as csvfile_23:
        csv_writer_23 = csv.writer(csvfile_23)
        csv_writer_23.writerow([
            f"{round(timestamp, 2)} s",
            f"{position.x:.2f} m" if position else "N/A",
            f"{position.y:.2f} m" if position else "N/A",
            f"{position.z:.2f} m" if position else "N/A",
            f"{velocity.x:.2f} m/s" if velocity else "N/A",
            f"{velocity.y:.2f} m/s" if velocity else "N/A",
            f"{velocity.z:.2f} m/s" if velocity else "N/A",
            pitch, roll, yaw,
            f"{yellow_line_offset} pixels",
            rotation_data[0],  # åŠ¨æ€æ•°æ®
            rotation_data[1],
            rotation_data[2]
        ])
    print("Data recorded to CSV.")

    # Define the folder to save captured images (JPG format)
    folder_path = '/home/dym/course2yuan_PID_images'

    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    # Generate a unique filename
    image_filename = f"image_{image_counter}.jpg"
    image_counter += 1

    # Save the captured image
    file_path = os.path.join(folder_path, image_filename)
    cv2.imwrite(file_path, small_image)
    print(f"Image saved as JPG: {file_path}")

    # Convert the OpenCV image to a NumPy array
    frame = np.array(small_image)

    # è·å–å¹³æ»‘åçš„å½¢çŠ¶ä»£ç 
    shape_code, smoothed_shape_code = process_image_and_get_shape_code(cv_image)

    last_shape_code = int(last_shape_code)
    smoothed_shape_code = int(smoothed_shape_code)

    ### æ­¥éª¤ 1: å¤„ç† T å½¢æ ‡å¿— ###
    if not tracking_active and smoothed_shape_code == 5:
        tracking_active = True
        tracking_state = 'T_left'
        print("Started tracking T left transition.")

    if tracking_active and tracking_state == 'T_left' and smoothed_shape_code == 9:
        t_left_count += 1
        print(f"T left transition completed. T left count: {t_left_count}")
        tracking_active = False
        tracking_state = None

        if t_left_count == 1:
            print("First T left detected.")
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif t_left_count == 2:
            print("Second T left detected, rotating counterclockwise 90 degrees.")
            pause_movement = True
            # âœ… æ­£ç¡®è°ƒç”¨æ—‹è½¬å‡½æ•°ï¼Œè·å–æ—¶é—´æ•°æ®
            rotation_start_time, rotation_end_time, rotation_duration = rotate_counterclockwise_90(vehicle)

            # âœ… é¿å… `NoneType` é”™è¯¯
            if rotation_start_time is not None and rotation_end_time is not None:
                print(f"ğŸ“Œ Rotation Start Time: {rotation_start_time:.2f} s")
                print(f"ğŸ“Œ Rotation End Time: {rotation_end_time:.2f} s")
                print(f"ğŸ“Œ Rotation Duration: {rotation_duration:.2f} s")

            pause_movement = False


        return

    ### æ­¥éª¤ 2: å¤„ç†äº¤å‰æ ‡å¿— ###
    if not tracking_active and smoothed_shape_code == 7:
        tracking_active = True
        tracking_state = 'Cross'
        print("Started tracking Cross transition.")

    if tracking_active and tracking_state == 'Cross' and smoothed_shape_code == 3:
        cross_count += 1
        print(f"Cross transition completed. Cross count: {cross_count}")
        tracking_active = False
        tracking_state = None

        if cross_count == 1:
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif cross_count == 2:
            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
        elif cross_count == 3:
            print("Third cross detected. Position '23' reached.")
            pause_movement = True
            hover(vehicle, hover_time=5)
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")


            exit_flag = True

    elif smoothed_shape_code == 2:
        follow_yellow_line(vehicle, frame)

    cv2.imshow("frame", frame)
    cv2.waitKey(10)

    last_shape_code = smoothed_shape_code
    print(f"Last shape code after update: {last_shape_code}")


def image_callback_53(msg):
    global camera_subscriber, t_left_count, phase, last_shape_code, pause_movement, exit_flag, image_counter
    global tracking_active, tracking_state
    global start_timer_53_initialized, start_time_53
    global current_pose, current_twist, current_pitch, current_roll, current_yaw  # ä½¿ç”¨æ–°çš„å…¨å±€å˜é‡
    global rotation_start_time, rotation_end_time, rotation_duration, is_rotating

    print(f"Last shape code before processing: {last_shape_code}")
    # **æ·»åŠ æ—¶é—´æˆ³çš„è®¡ç®—**
    if not start_timer_53_initialized:
        start_time_53 = time.time()
        start_timer_53_initialized = True
        print("Timer initialized for image_callback_53.")
        rotation_start_time = None  # é‡ç½®ä»»ä½•å·²æœ‰çš„æ—‹è½¬æ—¶é—´
    timestamp = time.time() - start_time_53  # âœ… **æ·»åŠ è¿™ä¸€è¡Œ**

    with data_lock:
        if is_rotating and rotation_start_time is not None and start_time_53 is not None:
            # æ­£åœ¨æ—‹è½¬ä¸­çš„çŠ¶æ€
            rotation_data = [
                f"{rotation_start_time - start_time_53:.2f}",
                "Rotating",
                "Calculating"
            ]
        elif rotation_duration is not None and rotation_start_time is not None and rotation_end_time is not None and start_time_53 is not None:
            # æ—‹è½¬å®Œæˆåçš„å®Œæ•´è®°å½•
            rotation_data = [
                f"{rotation_start_time - start_time_53:.2f}",
                f"{rotation_end_time - start_time_53:.2f}",
                f"{rotation_duration:.2f}"
            ]
            # å•æ¬¡è®°å½•åé‡ç½®
            rotation_start_time = rotation_end_time = rotation_duration = None
        else:
            # å¦‚æœæ—‹è½¬æ•°æ®æœªåˆå§‹åŒ–ï¼Œé¿å…æŠ¥é”™
            rotation_data = ["N/A", "N/A", "N/A"]

    # è·å–æ— äººæœºçŠ¶æ€ä¿¡æ¯
    position = current_pose.position if current_pose else None
    velocity = current_twist.linear if current_twist else None
    # ä½¿ç”¨ Gazebo æå–çš„å§¿æ€ä¿¡æ¯
    pitch = current_pitch if current_pitch is not None else None
    roll = current_roll if current_roll is not None else None
    yaw = current_yaw if current_yaw is not None else None

    # è½¬æ¢ ROS å›¾åƒæ¶ˆæ¯ä¸º OpenCV å›¾åƒ
    cv_image = bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
    small_image = cv2.resize(cv_image, (400, 400))
    # è®¡ç®—å›¾åƒä¸­å¿ƒä¸é»„çº¿ä¸­å¿ƒçš„è·ç¦»
    yellow_line_offset = calculate_yellow_line_offset(small_image)  # è‡ªå®šä¹‰å‡½æ•°

    # ä¿å­˜æ•°æ®åˆ° CSV
    with open(data_file_path_53, 'a', newline='') as csvfile_53:
        csv_writer_53 = csv.writer(csvfile_53)
        csv_writer_53.writerow([
            f"{round(timestamp, 2)} s",
            f"{position.x:.2f} m" if position else "N/A",
            f"{position.y:.2f} m" if position else "N/A",
            f"{position.z:.2f} m" if position else "N/A",
            f"{velocity.x:.2f} m/s" if velocity else "N/A",
            f"{velocity.y:.2f} m/s" if velocity else "N/A",
            f"{velocity.z:.2f} m/s" if velocity else "N/A",
            pitch, roll, yaw,
            f"{yellow_line_offset} pixels",
            rotation_data[0],  # åŠ¨æ€æ•°æ®
            rotation_data[1],
            rotation_data[2]
        ])

    print("Data recorded to CSV.")
    
    # Define the folder to save captured images (JPG format before converting to EPS)
    folder_path = '/home/dym/course3yuan_PID_images'  # course0bian_images,course0yuan_images

    # Create the folder if it does not exist
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    # Generate a unique filename based on the counter value (JPG format)
    image_filename = f"image_{image_counter}.jpg"

    # Increment the counter for the next image
    image_counter += 1

    # Construct the full file path to save the image in JPG format
    file_path = os.path.join(folder_path, image_filename)

    # Save the captured image in JPG format (for now)
    cv2.imwrite(file_path, small_image)
    print(f"Image saved as JPG: {file_path}")
    # Convert the OpenCV image to a NumPy array
    frame = np.array(small_image)  # Use the resized image
    # è·å–å¹³æ»‘åçš„å½¢çŠ¶ä»£ç 
    shape_code, smoothed_shape_code = process_image_and_get_shape_code(cv_image)

    # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
    last_shape_code = int(last_shape_code)
    smoothed_shape_code = int(smoothed_shape_code)

    print(f"Last shape code: {last_shape_code}, Smoothed shape code: {smoothed_shape_code}")

    # ç¬¬ä¸€é˜¶æ®µé€»è¾‘ï¼šä» 5 åˆ° 9
    if phase == 1:
        if not tracking_active and smoothed_shape_code == 5:
            tracking_active = True
            tracking_state = "T_detecting"

        if tracking_active and tracking_state == "T_detecting" and smoothed_shape_code == 9:
            t_left_count += 1
            tracking_active = False  # åœæ­¢è·Ÿè¸ª
            print(f"T-shaped marker {t_left_count} detected in phase 1.")

            if t_left_count < 4:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
            elif t_left_count == 4:
                print("Fourth T-shaped marker detected. Proceeding to phase 2.")
                t_left_count = 0  # é‡ç½®è®¡æ•°å™¨
                phase = 2  # è¿›å…¥ç¬¬äºŒé˜¶æ®µ
        elif smoothed_shape_code == 2:
             # è°ƒç”¨è·¯å¾„è·Ÿè¸ªå‡½æ•°
            follow_yellow_line(vehicle, frame)


    # ç¬¬äºŒé˜¶æ®µé€»è¾‘ï¼šä» 2 åˆ° 5
    elif phase == 2:
        if smoothed_shape_code == 2:
            # è°ƒç”¨è·¯å¾„è·Ÿè¸ªå‡½æ•°
            follow_yellow_line(vehicle, frame)
        if not tracking_active and smoothed_shape_code == 2:
            tracking_active = True
            tracking_state = "Left_turn_detecting"
            
        if tracking_active and tracking_state == "Left_turn_detecting" and smoothed_shape_code == 5:
            print("Left turn detected. Rotating counterclockwise 90 degrees.")
            tracking_active = False  # åœæ­¢è·Ÿè¸ª
            pause_movement = True
            # âœ… æ­£ç¡®è°ƒç”¨æ—‹è½¬å‡½æ•°ï¼Œè·å–æ—¶é—´æ•°æ®
            rotation_start_time, rotation_end_time, rotation_duration = rotate_counterclockwise_90(vehicle)

            # âœ… é¿å… `NoneType` é”™è¯¯
            if rotation_start_time is not None and rotation_end_time is not None:
                print(f"ğŸ“Œ Rotation Start Time: {rotation_start_time:.2f} s")
                print(f"ğŸ“Œ Rotation End Time: {rotation_end_time:.2f} s")
                print(f"ğŸ“Œ Rotation Duration: {rotation_duration:.2f} s")

            send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
            pause_movement = False
            phase = 3  # è¿›å…¥ç¬¬ä¸‰é˜¶æ®µ

    # ç¬¬ä¸‰é˜¶æ®µé€»è¾‘ï¼šä» 5 åˆ° 9
    elif phase == 3:

        if not tracking_active and smoothed_shape_code == 5:
            tracking_active = True
            tracking_state = "T_detecting"

        if tracking_active and tracking_state == "T_detecting" and smoothed_shape_code == 9:
            t_left_count += 1
            tracking_active = False  # åœæ­¢è·Ÿè¸ª
            print(f"T-shaped marker {t_left_count} detected in phase 3.")

            if t_left_count < 3:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
            elif t_left_count == 3:

                print("Third T right detected. Position '53' reached.")

                # æš‚åœä¸»å¾ªç¯
                pause_movement = True

                # æ— äººæœºæ‚¬åœ
                hover(vehicle, hover_time=0)

                # åœæ­¢ç›¸æœºè®¢é˜…
                camera_subscriber.unregister()
                print("Camera subscriber stopped.")


                # è®¾ç½®é€€å‡ºæ ‡å¿—ï¼Œé€€å‡ºä¸»å¾ªç¯
                exit_flag = True
        elif smoothed_shape_code == 2 :

            # è°ƒç”¨è·¯å¾„è·Ÿè¸ªå‡½æ•°
            follow_yellow_line(vehicle, frame)

    # Display the image
    cv2.imshow("frame", frame)
    cv2.waitKey(10)
    # æ›´æ–°ä¸Šä¸€å¸§å½¢çŠ¶ä»£ç 
    last_shape_code = smoothed_shape_code
    print(f"Last shape code after update: {last_shape_code}")

# ä½ç½®å­—å…¸ï¼ˆåŒæ ·å¯ä»¥ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„positionså­—å…¸ï¼‰
positions = {
    '00': (0, 0),
    '01': (0, 1),
    '02': (0, 2),
    '03': (0, 3),
    '04': (0, 4),
    '10': (1, 0),
    '11': (1, 1),
    '12': (1, 2),
    '13': (1, 3),
    '14': (1, 4),
    '20': (2, 0),
    '21': (2, 1),
    '22': (2, 2),
    '23': (2, 3),
    '24': (2, 4),
    '30': (3, 0),
    '31': (3, 1),
    '32': (3, 2),
    '33': (3, 3),
    '34': (3, 4),
    '40': (4, 0),
    '41': (4, 1),
    '42': (4, 2),
    '43': (4, 3),
    '44': (4, 4),
    '50': (5, 0),
    '51': (5, 1),
    '52': (5, 2),
    '53': (5, 3),
    '54': (5, 4),
}

def fly_to_03():
    global camera_subscriber, pause_movement, exit_flag

    print("Flying logic for position 03")

    target_altitude = 0.5  # èµ·é£ç›®æ ‡é«˜åº¦ï¼ˆç±³ï¼‰
    forward_speed = 0.1  # å‰è¿›é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰

    # ç¡®ä¿ GUIDED æ¨¡å¼
    vehicle.mode = VehicleMode("GUIDED")
    while not vehicle.mode.name == "GUIDED":
        print("Waiting for vehicle to enter GUIDED mode")
        time.sleep(1)

    # æ— äººæœºè§£é”å¹¶èµ·é£
    arm_and_takeoff(target_altitude)
    print("Vehicle armed and took off")

    # Set up the subscriber to receive camera messages
    camera_topic = '/camera/image_raw'
    camera_subscriber = rospy.Subscriber(camera_topic, Image, image_callback_03)


    # è®¾ç½®ä¸»å¾ªç¯é¢‘ç‡
    loop_rate = rospy.Rate(30)  # ä¸»å¾ªç¯é¢‘ç‡ï¼ˆ10 Hzï¼‰

    try:
        # åœ¨ä¸»å¾ªç¯ä¸­æŒç»­å‰è¿›å¹¶å¤„ç†å›¾åƒæ•°æ®
        while not rospy.is_shutdown() and not exit_flag:  # æ£€æŸ¥ exit_flag æ§åˆ¶é€€å‡ºä¸»å¾ªç¯
            if not pause_movement:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
                print(f"Drone moving forward at {forward_speed} m/s")

            # ä¿æŒä¸»å¾ªç¯è¿è¡Œ
            loop_rate.sleep()

    except rospy.ROSInterruptException:
        print("ROS shutdown")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        # åœæ­¢æ— äººæœºè¿åŠ¨
        send_ned_velocity(vehicle, velocity_x=0, velocity_y=0, velocity_z=0, duration=1)
        print("Drone stopped.")

        # åœæ­¢ç›¸æœºè®¢é˜…
        if camera_subscriber:
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")

        # æ¸…ç†èµ„æºå¹¶ç»“æŸç¨‹åº
        if vehicle:
            vehicle.mode = VehicleMode("LAND")  # é™è½
            print("Landing vehicle.")

        print("Fly to 03 complete.")


def fly_to_13():
    global camera_subscriber, pause_movement, exit_flag

    print("Flying logic for position 13")

    target_altitude = 0.5  # èµ·é£ç›®æ ‡é«˜åº¦ï¼ˆç±³ï¼‰
    forward_speed = 0.1  # å‰è¿›é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰

    # ç¡®ä¿ GUIDED æ¨¡å¼
    vehicle.mode = VehicleMode("GUIDED")
    while not vehicle.mode.name == "GUIDED":
        print("Waiting for vehicle to enter GUIDED mode")
        time.sleep(1)

    # æ— äººæœºè§£é”å¹¶èµ·é£
    arm_and_takeoff(target_altitude)
    print("Vehicle armed and took off")

    # é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
    rotate_clockwise_90(vehicle)  # è°ƒç”¨é¡ºæ—¶é’ˆæ—‹è½¬å‡½æ•°
    print("é¡ºæ—¶é’ˆæ—‹è½¬å®Œæˆï¼Œç»§ç»­å‘å‰ç§»åŠ¨...")
    hover(vehicle, hover_time=2)

    # Set up the subscriber to receive camera messages
    camera_topic = '/camera/image_raw'
    camera_subscriber = rospy.Subscriber(camera_topic, Image, image_callback_13)


    # è®¾ç½®ä¸»å¾ªç¯é¢‘ç‡
    loop_rate = rospy.Rate(30)  # ä¸»å¾ªç¯é¢‘ç‡ï¼ˆ10 Hzï¼‰

    try:
        # åœ¨ä¸»å¾ªç¯ä¸­æŒç»­å‰è¿›å¹¶å¤„ç†å›¾åƒæ•°æ®
        while not rospy.is_shutdown() and not exit_flag:  # æ£€æŸ¥ exit_flag æ§åˆ¶é€€å‡ºä¸»å¾ªç¯
            if not pause_movement:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
                print(f"Drone moving forward at {forward_speed} m/s")

            # ä¿æŒä¸»å¾ªç¯è¿è¡Œ
            loop_rate.sleep()


    except rospy.ROSInterruptException:
        print("ROS shutdown")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        # åœæ­¢æ— äººæœºè¿åŠ¨
        send_ned_velocity(vehicle, velocity_x=0, velocity_y=0, velocity_z=0, duration=1)
        print("Drone stopped.")

        # åœæ­¢ç›¸æœºè®¢é˜…
        if camera_subscriber:
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")

        # æ¸…ç†èµ„æºå¹¶ç»“æŸç¨‹åº
        if vehicle:
            vehicle.mode = VehicleMode("LAND")  # é™è½
            print("Landing vehicle.")

        print("Fly to 13 complete.")



def fly_to_23():
    global camera_subscriber, pause_movement, exit_flag

    print("Flying logic for position 23")

    target_altitude = 0.5  # èµ·é£ç›®æ ‡é«˜åº¦ï¼ˆç±³ï¼‰
    forward_speed = 0.1  # å‰è¿›é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰
    # ç¡®ä¿ GUIDED æ¨¡å¼
    vehicle.mode = VehicleMode("GUIDED")
    while not vehicle.mode.name == "GUIDED":
        print("Waiting for vehicle to enter GUIDED mode")
        time.sleep(1)
    # æ— äººæœºè§£é”å¹¶èµ·é£
    arm_and_takeoff(target_altitude)
    print("Vehicle armed and took off")

    # é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
    rotate_clockwise_90(vehicle)  # è°ƒç”¨é¡ºæ—¶é’ˆæ—‹è½¬å‡½æ•°
    print("é¡ºæ—¶é’ˆæ—‹è½¬å®Œæˆï¼Œç»§ç»­å‘å‰ç§»åŠ¨...")

    # Set up the subscriber to receive camera messages
    camera_topic = '/camera/image_raw'
    camera_subscriber = rospy.Subscriber(camera_topic, Image, image_callback_23)


    # è®¾ç½®ä¸»å¾ªç¯é¢‘ç‡
    loop_rate = rospy.Rate(30)  # ä¸»å¾ªç¯é¢‘ç‡ï¼ˆ10 Hzï¼‰

    try:
        # åœ¨ä¸»å¾ªç¯ä¸­æŒç»­å‰è¿›å¹¶å¤„ç†å›¾åƒæ•°æ®
        while not rospy.is_shutdown() and not exit_flag:  # æ£€æŸ¥ exit_flag æ§åˆ¶é€€å‡ºä¸»å¾ªç¯
            if not pause_movement:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
                print(f"Drone moving forward at {forward_speed} m/s")

            # ä¿æŒä¸»å¾ªç¯è¿è¡Œ
            loop_rate.sleep()

    except rospy.ROSInterruptException:
        print("ROS shutdown")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        # åœæ­¢æ— äººæœºè¿åŠ¨
        send_ned_velocity(vehicle, velocity_x=0, velocity_y=0, velocity_z=0, duration=1)
        print("Drone stopped.")

        # åœæ­¢ç›¸æœºè®¢é˜…
        if camera_subscriber:
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")

        # æ¸…ç†èµ„æºå¹¶ç»“æŸç¨‹åº
        if vehicle:
            vehicle.mode = VehicleMode("LAND")  # é™è½
            print("Landing vehicle.")

        print("Fly to 23 complete.")


def fly_to_33():
    print("Flying logic for position 33")
    # Add your drone control code here
    pass


def fly_to_43():
    print("Flying logic for position 43")
    # Add your drone control code here
    pass

def fly_to_53():
    global camera_subscriber, pause_movement, exit_flag

    print("Flying logic for position 53")

    target_altitude = 0.5  # èµ·é£ç›®æ ‡é«˜åº¦ï¼ˆç±³ï¼‰
    forward_speed = 0.1  # å‰è¿›é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰

    # ç¡®ä¿ GUIDED æ¨¡å¼
    vehicle.mode = VehicleMode("GUIDED")
    while not vehicle.mode.name == "GUIDED":
        print("Waiting for vehicle to enter GUIDED mode")
        time.sleep(1)
    # æ— äººæœºè§£é”å¹¶èµ·é£
    arm_and_takeoff(target_altitude)
    print("Vehicle armed and took off")

    # é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
    rotate_clockwise_90(vehicle)  # è°ƒç”¨é¡ºæ—¶é’ˆæ—‹è½¬å‡½æ•°
    print("é¡ºæ—¶é’ˆæ—‹è½¬å®Œæˆï¼Œç»§ç»­å‘å‰ç§»åŠ¨...")


    # Set up the subscriber to receive camera messages
    camera_topic = '/camera/image_raw'
    camera_subscriber = rospy.Subscriber(camera_topic, Image, image_callback_53)
    

    # è®¾ç½®ä¸»å¾ªç¯é¢‘ç‡
    loop_rate = rospy.Rate(30)  # ä¸»å¾ªç¯é¢‘ç‡ï¼ˆ10 Hzï¼‰

    try:
        # åœ¨ä¸»å¾ªç¯ä¸­æŒç»­å‰è¿›å¹¶å¤„ç†å›¾åƒæ•°æ®
        while not rospy.is_shutdown() and not exit_flag:  # æ£€æŸ¥ exit_flag æ§åˆ¶é€€å‡ºä¸»å¾ªç¯
            if not pause_movement:
                send_ned_velocity(vehicle, velocity_x=forward_speed, velocity_y=0, velocity_z=0, duration=0.1)
                print(f"Drone moving forward at {forward_speed} m/s")

            # ä¿æŒä¸»å¾ªç¯è¿è¡Œ
            loop_rate.sleep()

    except rospy.ROSInterruptException:
        print("ROS shutdown")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        # åœæ­¢æ— äººæœºè¿åŠ¨
        send_ned_velocity(vehicle, velocity_x=0, velocity_y=0, velocity_z=0, duration=1)
        print("Drone stopped.")

        # åœæ­¢ç›¸æœºè®¢é˜…
        if camera_subscriber:
            camera_subscriber.unregister()
            print("Camera subscriber stopped.")

        # æ¸…ç†èµ„æºå¹¶ç»“æŸç¨‹åº
        if vehicle:
            vehicle.mode = VehicleMode("LAND")  # é™è½
            print("Landing vehicle.")

        print("Fly to 53 complete.")

#ç»§ç»­æ·»åŠ å…¶ä»–ä½ç½®çš„é£è¡Œé€»è¾‘...

# é£è¡Œè·¯çº¿æ˜ å°„
flight_routes = {
    '03': fly_to_03,
    '13': fly_to_13,
    '23': fly_to_23,
    '33': fly_to_33,
    '43': fly_to_43,
    '53': fly_to_53,
}

def main():
    global vehicle

    # è¯·æ±‚ç”¨æˆ·è¾“å…¥ç›®æ ‡ä½ç½®å¹¶éªŒè¯
    while True:
        target_position = input("Enter the target position (e.g., 00, 01, ..., 54): ")

        if target_position in flight_routes:
            break  # æœ‰æ•ˆä½ç½®ï¼Œé€€å‡ºå¾ªç¯
        else:
            print("Invalid input. Please enter a valid position code (e.g., 00, 01, 02).")

    # æ ¹æ®ç›®æ ‡ä½ç½®çš„å¼€å¤´æ•°å­—å†³å®šæ‰§è¡Œé€»è¾‘
    print(f"Flying to target position {target_position}")

    if target_position.startswith('0'):
        # ç›®æ ‡ä½ç½®ä»¥ '0' å¼€å¤´ï¼Œç›´æ¥æ‰§è¡Œç¨‹åº
        flight_routes[target_position]()  # è°ƒç”¨ç›¸åº”çš„é£è¡Œé€»è¾‘å‡½æ•°
    elif target_position.startswith('1'):
        flight_routes[target_position]()  
    elif target_position.startswith('2'):
        flight_routes[target_position]()
    elif target_position.startswith('3'):
        flight_routes[target_position]()
    elif target_position.startswith('4'):
        flight_routes[target_position]()
    elif target_position.startswith('5'):
        flight_routes[target_position]()
if __name__ == "__main__":
    main()

